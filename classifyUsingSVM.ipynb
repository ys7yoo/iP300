{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "## Let's start from linear SVM \n",
    "from sklearn.svm import LinearSVC\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load one epoch data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_one_epoch(subject, data_type, epoch_num):\n",
    "    if data_type is 'train':\n",
    "        epoch_data=loadmat(\"data/{}{}-allfilt20.mat\".format(subject, epoch_num))\n",
    "\n",
    "    x=epoch_data['x']\n",
    "    y=epoch_data['y']\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject='A'\n",
    "epoch_num = 1\n",
    "x, y = load_one_epoch(subject, 'train', 1)\n",
    "\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load all training data for a subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(subject, data_type, num_epoches):\n",
    "    X = list()\n",
    "    Y = list()\n",
    "    for epoch_num in range(num_epoches):\n",
    "        #print(epoch_num)\n",
    "        x, y = load_one_epoch(subject, data_type, 1+epoch_num)\n",
    "\n",
    "        X.append(x)\n",
    "        Y.append(y)\n",
    "\n",
    "\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "\n",
    "    print('loaded:')\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "\n",
    "    num_trials = X.shape[1]\n",
    "    data_dim = X.shape[2]\n",
    "\n",
    "    # stack epoches\n",
    "    X = X.reshape(-1,data_dim)\n",
    "    Y = Y.reshape(-1,1)\n",
    "\n",
    "    print('stacked:')\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "subject = 'A'\n",
    "#subject = 'B'\n",
    "num_epoches = 85\n",
    "\n",
    "X_train, Y_train = load_data(subject, 'train', num_epoches)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load and apply channel masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_channel_mask(subject, num_channels):\n",
    "    return np.loadtxt('mask/{}_chosen_channel_mask_{}.txt'.format(subject,num_channels), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = load_channel_mask(subject,2)\n",
    "#plt.plot(mask)\n",
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_mask(X, mask):\n",
    "    data_dim = X.shape[1]\n",
    "    num_channels = len(mask)\n",
    "    samples_per_channel = int(data_dim / num_channels)\n",
    "    \n",
    "#     print(X.shape)\n",
    "#     print(data_dim)\n",
    "#     print(num_channels)\n",
    "#     print(samples_per_channel)    \n",
    "    \n",
    "    index = np.repeat(mask,samples_per_channel)\n",
    "    \n",
    "#     print(mask)\n",
    "#     print(np.repeat(mask,samples_per_channel))\n",
    "\n",
    "    return X[:,index>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15300, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_chosen=apply_mask(X_train, mask)\n",
    "X_train_chosen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15300, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try training without scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yyoo/tf11/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=5000, multi_class='ovr',\n",
       "     penalty='l2', random_state=42, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try training\n",
    "clf = svm.LinearSVC(C=10, loss=\"hinge\", max_iter=5000, random_state=42)  # class_weight='balanced',\n",
    "\n",
    "clf.fit(X_train_chosen,Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6947276688453159\n",
      "0.46052267586522366\n"
     ]
    }
   ],
   "source": [
    "# training classfication error\n",
    "Yhat = clf.predict(X_train_chosen)\n",
    "print(np.mean(Y_train==Yhat))\n",
    "print(np.std(Y_train==Yhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling matters!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yyoo/tf11/lib/python3.7/site-packages/sklearn/svm/base.py:922: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scaler', StandardScaler(copy=True, with_mean=True, with_std=True)), ('linear_svc', LinearSVC(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=5000, multi_class='ovr',\n",
       "     penalty='l2', random_state=42, tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## with scaling\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=10, loss=\"hinge\", max_iter=5000, random_state=42)), # class_weight='balanced', \n",
    "    ])\n",
    "\n",
    "clf.fit(X_train_chosen,Y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8333333333333334\n",
      "0.3726779962500039\n"
     ]
    }
   ],
   "source": [
    "# training classfication error\n",
    "Yhat = clf.predict(X_train_chosen)\n",
    "print(np.mean(Y_train==Yhat))\n",
    "print(np.std(Y_train==Yhat))\n",
    "\n",
    "## SCALING IS IMPORTANT!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**below is old code from https://github.com/ys7yoo/human-plus/blob/master/classifyUsingSVM.ipynb**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's do cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "# linear classifier\n",
    "clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=10, loss=\"hinge\",  random_state=42)), # class_weight='balanced',\n",
    "    ])\n",
    "\n",
    "# run cross validation\n",
    "scores = cross_val_score(clf, X, Y, cv=5)\n",
    "\n",
    "print(scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for a wide range of C\n",
    "Cs = 10**np.linspace(-20,20,41)\n",
    "Cs\n",
    "\n",
    "k = 5\n",
    "scores = list()\n",
    "for C in Cs:\n",
    "    clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=C, loss=\"hinge\",  random_state=42)), # class_weight='balanced',\n",
    "    ])\n",
    "\n",
    "    scores.append(cross_val_score(clf, X, Y, cv=k))\n",
    "    \n",
    "#scores\n",
    "\n",
    "mean_scores = np.mean(scores,axis=1)\n",
    "#print(mean_scores)\n",
    "\n",
    "maxIdx=np.argmax(mean_scores)\n",
    "print(\"max accuracy = {} when C={}\".format(mean_scores[maxIdx], Cs[maxIdx]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(np.log10(Cs),mean_scores)\n",
    "plt.plot(np.log10(Cs), baseAcc*np.ones_like(Cs), '--')\n",
    "plt.xlabel('log_10(C)')\n",
    "plt.ylabel('accuracy')\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Adding `balancing` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for a wide range of C\n",
    "Cs = 10**np.linspace(-20,20,41)\n",
    "Cs\n",
    "\n",
    "k = 5\n",
    "scores = list()\n",
    "for C in Cs:\n",
    "    clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"linear_svc\", LinearSVC(C=C, loss=\"hinge\",  class_weight='balanced', random_state=42)),  # balanced!\n",
    "    ])\n",
    "\n",
    "    scores.append(cross_val_score(clf, X, Y, cv=k))\n",
    "    \n",
    "#scores\n",
    "\n",
    "mean_scores_balanced = np.mean(scores,axis=1)\n",
    "#print(mean_scores_balanced)\n",
    "\n",
    "maxIdx=np.argmax(mean_scores_balanced)\n",
    "print(\"max accuracy = {} when C={}\".format(mean_scores_balanced[maxIdx], Cs[maxIdx]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(np.log10(Cs),mean_scores)\n",
    "plt.plot(np.log10(Cs),mean_scores_balanced)\n",
    "plt.plot(np.log10(Cs), baseAcc*np.ones_like(Cs), '--')\n",
    "plt.legend(('equal weight','balanced', 'baseline'))\n",
    "plt.xlabel('log_10(C)')\n",
    "plt.ylabel('accuracy')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's repeat & check confusion matrix!\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"linear_svc\", LinearSVC(C=10, loss=\"hinge\", random_state=42)),  # balanced!\n",
    "    #(\"linear_svc\", LinearSVC(C=10, loss=\"hinge\",  class_weight='balanced', random_state=42)),  # balanced!\n",
    "])\n",
    "    \n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=5, test_size=1/5, random_state=42)\n",
    "\n",
    "k = 0\n",
    "\n",
    "acc_train = list()\n",
    "acc_test = list()\n",
    "for train_index, test_index in split.split(X,Y):\n",
    "#    print(train_index)\n",
    "#    print(test_index)\n",
    "    if k==0:   # print info\n",
    "        print(\"In the training set of size{},\".format(Y[train_index].shape))\n",
    "        print(\"cor: {}, incor: {}\".format(sum(Y[train_index]==1),sum(Y[train_index]==-1)))\n",
    "        print(\"In the training set of size{},\".format(Y[test_index].shape))    \n",
    "        print(\"cor: {}, incor: {}\".format(sum(Y[test_index]==1),sum(Y[test_index]==-1)))\n",
    "        baseAcc = sum(Y[test_index]==1) / (sum(Y[test_index]==1)+sum(Y[test_index]==-1)) \n",
    "        print(\"base accuracy = {}\".format(baseAcc))\n",
    "\n",
    "    X_train = X[train_index,:]\n",
    "    Y_train = Y[train_index]\n",
    "    X_test = X[test_index,:]    \n",
    "    Y_test = Y[test_index]\n",
    "    \n",
    "    clf.fit(X_train,Y_train)\n",
    "\n",
    "    # training error\n",
    "    Yhat_train = clf.predict(X_train)\n",
    "    acc_train.append(np.mean(Yhat_train==Y_train))\n",
    "\n",
    "    # test error\n",
    "    Yhat_test = clf.predict(X_test)\n",
    "    acc_test.append(np.mean(Yhat_test==Y_test))\n",
    " \n",
    "    cm = confusion_matrix(Y_test, Yhat_test, labels=(1,-1))\n",
    "    print(cm)\n",
    "\n",
    "#     # let's manually check\n",
    "#     print(sum((Y_test == 1) & (Yhat_test == 1)))    # 1s are (correctly) predicted as 1s\n",
    "#     print(sum((Y_test == 1) & (Yhat_test == -1)))   # 1s are predicted as -1\n",
    "#     print(sum((Y_test == -1) & (Yhat_test == 1)))   # -1s are predicted as 1\n",
    "#     print(sum((Y_test == -1) & (Yhat_test == -1)))  # -1s are (correctly) predicted as -1\n",
    "\n",
    "    \n",
    "    k = k + 1\n",
    "print(\"training accuracy\")    \n",
    "print(acc_train)\n",
    "print(\"test accuracy\")    \n",
    "print(acc_test)\n",
    "print(np.mean(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-train using all the data (CAN I DO THIS?)\n",
    "\n",
    "clf.fit(X,Y)\n",
    "\n",
    "# get coefficient of SVM\n",
    "w = clf.named_steps['linear_svc'].coef_\n",
    "w = w.ravel()\n",
    "#w.shape\n",
    "plt.plot(w)\n",
    "plt.ylabel('w')\n",
    "plt.xlabel('feature index')\n",
    "\n",
    "\n",
    "w.shape\n",
    "#listSelectedFeature.shape\n",
    "listSelectedFeature[w>0.1,:]\n",
    "\n",
    "listSelectedFeature[w<-0.1,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So, conclusions are\n",
    "* linear SVM does *NOT* work for p<0.05\n",
    "* linear SVM does workf for p<0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear SVMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "rbf_kernel_svm_clf = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svm_clf\", svm.SVC(kernel=\"rbf\", gamma=2, C=10,random_state=42))   # class_weight='balanced',\n",
    "    ])\n",
    "    \n",
    "rbf_kernel_svm_clf.fit(X, Y)\n",
    "\n",
    "Yhat=rbf_kernel_svm_clf.predict(X)\n",
    "print(np.mean(Y==Yhat))\n",
    "plt.plot(Yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation with nonlinear SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat for a wide range of gamma and C\n",
    "\n",
    "Gs=2**np.linspace(-7,3,11)\n",
    "Gs\n",
    "Cs = 10**np.linspace(-20,20,41)\n",
    "Cs\n",
    "\n",
    "\n",
    "# unbalanced \n",
    "k = 5\n",
    "gs = list()\n",
    "cs = list()\n",
    "scores = list()\n",
    "for G in Gs:\n",
    "    print(\"gamma={}\".format(G))\n",
    "    for C in Cs:\n",
    "        rbf_kernel_svm_clf = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svm_clf\", svm.SVC(kernel=\"rbf\", gamma=G, C=C,random_state=42))   # class_weight='balanced',\n",
    "        ])\n",
    "        gs.append(G)\n",
    "        cs.append(C)\n",
    "        scores.append(cross_val_score(rbf_kernel_svm_clf, X, Y, cv=k))\n",
    "\n",
    "\n",
    "mean_scores = np.mean(scores,axis=1)\n",
    "#print(mean_scores)    \n",
    "\n",
    "\n",
    "maxIdx=np.argmax(mean_scores)\n",
    "print(\"max accuracy = {} when gamma={} and C={}\".format(mean_scores[maxIdx], gs[maxIdx], cs[maxIdx]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# save results to files\n",
    "np.savetxt(\"gamma.txt\", gs)\n",
    "np.savetxt(\"C.txt\", Cs)\n",
    "np.savetxt(\"scores.txt\", scores)\n",
    "np.savetxt(\"mean_scores.txt\", mean_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(mean_scores)\n",
    "#plt.plot(np.log10(Cs), mean_scores)\n",
    "plt.plot(baseAcc*np.ones_like(mean_scores), '--')\n",
    "plt.xlabel('(gamma,C)')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.8905555555555555*9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add balance\n",
    "\n",
    "Gs=2**np.linspace(-7,3,11)\n",
    "Gs\n",
    "Cs = 10**np.linspace(-20,20,41)\n",
    "Cs\n",
    "\n",
    "\n",
    "# unbalanced \n",
    "k = 5\n",
    "gs = list()\n",
    "cs = list()\n",
    "scores_balanced = list()\n",
    "for G in Gs:\n",
    "    print(\"gamma={}\".format(G))\n",
    "    for C in Cs:\n",
    "        rbf_kernel_svm_clf = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svm_clf\", svm.SVC(kernel=\"rbf\", gamma=G, C=C, class_weight='balanced', random_state=42))   # ,\n",
    "        ])\n",
    "        gs.append(G)\n",
    "        cs.append(C)\n",
    "        scores_balanced.append(cross_val_score(rbf_kernel_svm_clf, X, Y, cv=k))\n",
    "\n",
    "\n",
    "mean_scores_balanced = np.mean(scores_balanced,axis=1)\n",
    "#print(mean_scores)    \n",
    "\n",
    "\n",
    "maxIdx=np.argmax(mean_scores_balanced)\n",
    "print(\"max accuracy = {} when gamma={} and C={}\".format(mean_scores_balanced[maxIdx], gs[maxIdx], cs[maxIdx]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# save results to files\n",
    "np.savetxt(\"gamma_balanced.txt\", gs)\n",
    "np.savetxt(\"C_balanced.txt\", Cs)\n",
    "np.savetxt(\"scores_balanced.txt\", scores_balanced)\n",
    "np.savetxt(\"mean_scores_balanced.txt\", mean_scores_balanced)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.plot(mean_scores)\n",
    "#plt.plot(np.log10(Cs), mean_scores)\n",
    "plt.plot(baseAcc*np.ones_like(mean_scores), '--')\n",
    "plt.xlabel('(gamma,C)')\n",
    "plt.ylabel('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refit using the best param\n",
    "rbf_kernel_svm_clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm_clf\", svm.SVC(kernel=\"rbf\", gamma=0.03125, C=1, class_weight='balanced', random_state=42))   # ,\n",
    "])\n",
    "\n",
    "rbf_kernel_svm_clf.fit(X,Y)\n",
    "\n",
    "# training error = 0\n",
    "Yhat = rbf_kernel_svm_clf.predict(X)\n",
    "np.mean(Yhat==Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's repeat & check confusion matrix!\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=5, test_size=1/5, random_state=42)\n",
    "\n",
    "k = 0\n",
    "\n",
    "acc_train = list()\n",
    "acc_test = list()\n",
    "for train_index, test_index in split.split(X,Y):\n",
    "#    print(train_index)\n",
    "#    print(test_index)\n",
    "    if k==0:   # print info\n",
    "        print(\"In the training set of size{},\".format(Y[train_index].shape))\n",
    "        print(\"cor: {}, incor: {}\".format(sum(Y[train_index]==1),sum(Y[train_index]==-1)))\n",
    "        print(\"In the training set of size{},\".format(Y[test_index].shape))    \n",
    "        print(\"cor: {}, incor: {}\".format(sum(Y[test_index]==1),sum(Y[test_index]==-1)))\n",
    "        baseAcc = sum(Y[test_index]==1) / (sum(Y[test_index]==1)+sum(Y[test_index]==-1)) \n",
    "        print(\"base accuracy = {}\".format(baseAcc))\n",
    "\n",
    "    X_train = X[train_index,:]\n",
    "    Y_train = Y[train_index]\n",
    "    X_test = X[test_index,:]    \n",
    "    Y_test = Y[test_index]\n",
    "    \n",
    "    rbf_kernel_svm_clf.fit(X_train,Y_train)\n",
    "\n",
    "    # training error\n",
    "    Yhat_train = rbf_kernel_svm_clf.predict(X_train)\n",
    "    acc_train.append(np.mean(Yhat_train==Y_train))\n",
    "\n",
    "    # test error\n",
    "    Yhat_test = rbf_kernel_svm_clf.predict(X_test)\n",
    "    acc_test.append(np.mean(Yhat_test==Y_test))\n",
    " \n",
    "    cm = confusion_matrix(Y_test, Yhat_test, labels=(1,-1))\n",
    "    print(cm)\n",
    "\n",
    "#     # let's manually check\n",
    "#     print(sum((Y_test == 1) & (Yhat_test == 1)))    # 1s are (correctly) predicted as 1s\n",
    "#     print(sum((Y_test == 1) & (Yhat_test == -1)))   # 1s are predicted as -1\n",
    "#     print(sum((Y_test == -1) & (Yhat_test == 1)))   # -1s are predicted as 1\n",
    "#     print(sum((Y_test == -1) & (Yhat_test == -1)))  # -1s are (correctly) predicted as -1\n",
    "\n",
    "    \n",
    "    k = k + 1\n",
    "print(\"training accuracy\")    \n",
    "print(acc_train)\n",
    "print(\"test accuracy\")    \n",
    "print(acc_test)\n",
    "print(np.mean(acc_test))\n",
    "print(np.std(acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Yhat_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "8/9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
